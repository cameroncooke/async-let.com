---
title: 'The AI Coding Revolution: Magic or Mirage?'
pubDatetime: 2025-06-29T00:00:00.000Z
ogImage: ./agentic-reflections/ai-mirrage.png
tags:
  - AI
  - Agentic AI
  - Productivity
  - Reflection
description: >-
  A personal reflection on my experience with AI-driven coding tools and their
  impact on productivity and well-being
---
![The AI Coding Revolution: Magic or Mirage?](./agentic-reflections/ai-mirrage.png)
Over the past few weeks, I have found myself reflecting deeply on my experiences with AI agentic coding tools like Cursor and specifically Claude Code. Initially, these tools excited me greatly because they promised the potential to accelerate my product development, eliminate mundane tasks, and allow me to create software that previously seemed beyond my reach due to time constraints.

*Update 10 August 2025:* I wrote a follow-up exploring how I am actively rebalancing family life with AI-driven momentum: [Finding Balance in the AI Boom: Family, FOMO, and My Limits](/posts/family-fomo-and-ai/).

However, recently I have begun to feel differently. While undeniably impressive in capability, these tools have started to take a significant personal toll. Instead of reducing my coding workload, I now find myself investing considerable time mastering the art of AI collaboration: developing sophisticated strategies to work around inherent limitations. Rather than writing code directly, I spend my hours engineering environments to make these limited AI systems effective collaborators.

> "I traded the craft of coding for the constant coordination of AI workflows. My evenings and weekends are now dominated by agent supervision."

## The Reality of Immutable AI Minds

A fundamental challenge I have encountered is the inherently static nature of today's Large Language Models (LLMs). Despite their impressive capabilities, these models do not truly learn or adapt to my projects in the way a human engineer naturally would. They lack the ability to genuinely retain insights or build intuition, merely predicting the next token from the context provided.

Although tools built around these LLMs, like Claude Code, manage context effectively, the underlying limitations remain. The issue is not whether these tools provide useful functionality (they certainly do) but rather that they can never achieve true autonomy. I find myself continuously compensating for their static, context-bound limitations.

## Struggling with the Context Window

A significant frustration in my experience has been the limited "context window": the amount of information the AI can process at once. Despite various strategies and workarounds to handle this constraint, none genuinely solve the core issue. In practice, this means I constantly need to provide additional context or clarify intentions, which becomes increasingly burdensome as the complexity of my projects grows.

> "These AI tools are impressive but fundamentally limited: they reconstruct from context rather than genuinely understanding. I spend more time orchestrating than I would like."

## The Expertise Trade-Off

Some might argue that my struggles stem from user error: that I am not using these tools properly, not leveraging their full potential, or not investing enough effort in creating comprehensive rules files and workflows. This criticism may well be valid. However, this observation reveals another fundamental challenge: I find myself needing to become an expert in AI collaboration rather than focusing on becoming a better programmer.

The skills required to effectively manage AI agents (prompt engineering, context management, workflow optimisation, and understanding model limitations) represent a completely different expertise from software development itself. I am essentially exchanging one complex skill set for another, spending time mastering AI orchestration instead of deepening my programming knowledge or building actual products.

## The Double-Edged Success

To be fair, these tools have delivered genuine wins. Building my XcodeBuild MCP server would never have happened without AI assistance, and it has been thoroughly enjoyable. This project has built credibility, gained significant exposure, and helped boost my professional profile considerably. However, success creates its own pressure. I now feel an inherent obligation to keep the project maintained, up to date, and continuously delivering new features. This requires using AI faster and more effectively, creating a cycle where I am constantly chasing an elusive level of AI perfection that I may never reach.

## The Unexpected Cost: Personal Burnout

Initially, my motivation for using these tools was straightforward: I wanted to boost my productivity by reducing the amount of coding I had to perform directly. More importantly, I believed they would free up my time while allowing me to be creative and build products that I had dreamed of building but never had time to pursue. I bought into the compelling idea that, with sufficient fine-tuning, I could achieve a major breakthrough in productivity. Ironically, the reality has been the exact opposite.

I now find myself constantly checking my phone to see if my agents are working or need prompting to continue. I feel compelled to get up in the middle of the night to ensure I am using my subscription wisely, keeping Claude Code active during what should be downtime. This means I genuinely have no true downtime anymore because I want to maximise the value from these tools. The constant requirement for detailed oversight and fine-tuning has proven exhausting. Instead of saving time, I now spend nearly all of my spare hours keeping AI workflows running smoothly, which contradicts my original goal entirely.

> "The promise of automation fades quickly when you realise you have simply swapped one burden for another, supervising a forgetful and error-prone assistant."

## Reassessing My Priorities

Reflecting on these experiences has made me question how I balance AI-driven productivity with personal and family life. I have come to understand that true productivity should not come at the cost of personal happiness or family relationships. The pursuit of perfect AI workflows and automation is increasingly feeling like a mirage rather than a reality.

Moving forward, I am committed to finding a healthier balance. I intend to keep using these powerful tools but with a more realistic understanding of their capabilities and limitations. It is about setting clearer boundaries and expectations: prioritising meaningful productivity rather than chasing an elusive ideal of effortless automation.

## Confronting My Fear of Missing Out

Part of my struggle comes from a fear of missing out (FOMO), pushing me to stay ahead or at least on pace within my community. The AI boom is massively hyped, and everyone seems to be talking about and using these tools. From my social media feeds to professional circles, I see this divide: some people are completely unaware of what is happening with AI and agentic software engineering, while others are at the cutting edge. I fundamentally do not want to be left behind or become irrelevant. While I remain excited about the ongoing developments and future potential of these technologies, I recognise the need to step back and reassess their true value to me personally.

I am not planning to stop building with AI-driven tools. In fact, you will likely see me continuing to explore and discuss them frequently. However, I will do so with a renewed focus on maintaining a healthier "AI-life balance." Instead of pursuing an idealised vision of effortless productivity, my goal is to ensure my personal life, family time, and overall well-being remain central priorities.

This article is my honest reflection on the tension between ambition, productivity, and personal fulfilment. It is not a dismissal of AI technology but rather an acknowledgment that balancing innovation and personal well-being is essential.
