---
title: "Claude Code's MCP Token Reporting Needs a Second Look"
description: Evidence that Claude Code's /context command inflates MCP server token usage and what that means for the current debate.
pubDatetime: 2025-11-15T00:00:00.000Z
tags:
  - MCP
  - Tokens
  - Claude Code
  - Agents
---

The criticism I often hear about MCP servers is that they eat most of the context window before an agent can answer even a trivial question. I wanted to see if that was real payload or a measurement artefact, so I captured raw API calls and replicated Claude Code's counting.

## TL;DR

- Claude Code's `/context` sums per-tool `count_tokens` calls, so platform system instructions and wrapper text are charged once for each tool.
- XcodeBuildMCP's tools occupy ~14k-15k tokens in a single request, but `/context` reports ~45k because Anthropic's hidden system instructions and the wrapper are repeated 60 times.
- Users see a roughly 3x overstatement in the MCP line item. MCPs still have a real cost, but the UI exaggerates it.

## Background: where the token bloat story started

Claude Code is a terminal coding agent that uses Anthropic's large language models. Its `/context` slash command prints a live breakdown of how many tokens each section of the prompt is consuming: system prompt, built-in tools, MCP tools, memory files, messages, and free space. When XcodeBuildMCP is installed, the panel looks like this:

```
/context

  Context Usage
 ⛁ ... ⛁   claude-sonnet-4-5-20250929 · 112k/200k tokens (56%)
 ⛁ ... ⛁
 ⛁ ... ⛁   ⛁ System prompt: 2.5k tokens (1.2%)
 ⛀ ... ⛶   ⛁ System tools: 13.8k tokens (6.9%)
 ⛶ ... ⛝   ⛁ MCP tools: 45.0k tokens (22.5%)
 ⛶ ... ⛶   ⛁ Memory files: 5.9k tokens (2.9%)
 ⛶ ... ⛶   ⛁ Messages: 8 tokens (0.0%)
 ⛶ ... ⛝   ⛶ Free space: 88k (43.9%)
 ⛝ ... ⛝   ⛝ Autocompact buffer: 45.0k tokens (22.5%)

 MCP tools · /mcp
 └ mcp__XcodeBuildMCP__build_device (XcodeBuildMCP): 813 tokens
 └ mcp__XcodeBuildMCP__clean (XcodeBuildMCP): 955 tokens
 └ … (62 more tools ranging from ~600-1,100 tokens each)
```

Seeing 45k tokens allocated to "MCP tools" before typing a prompt cemented the narrative that MCP servers burn half the context window. Many users responded by disabling MCP servers or switching to CLI-only workflows.

## Why the numbers looked so high

I built a small usage-reporting tool that measured the MCP payload independently and it consistently showed ~14k tokens for XcodeBuildMCP's tools. Claude Code, however, insisted on 45k. The `/context` output is generated by calling Anthropic's `count_tokens` API for each tool and summing the results.

## What I measured

### Single request versus per-tool sums

| Component                                               | Tokens     |
| ------------------------------------------------------- | ---------- |
| XcodeBuildMCP tool JSON (tokeniser)                     | **14,081** |
| `count_tokens` call with all tools in one request       | **15,282** |
| `/context` "MCP tools" total (per-tool summed requests) | **45,018** |
| Implied hidden instructions + wrapper text (difference) | **30,937** |

The tool surface occupies ~14k tokens when measured directly, becomes ~15k once Anthropic adds its shared system instructions plus wrapper for a single request, yet `/context` reports ~45k. Remove the tools and keep the wrapper and the total collapses to hundreds of tokens, showing most of the gap is duplicated platform instructions rather than the tool bodies.

> "/context" is summing the platform system prompt and wrapper once per tool instead of once per request. That duplication explains almost the entire 30k-token gap.

### Per-tool counting repeats the wrapper and system instructions

Claude Code queries Anthropic's `count_tokens` endpoint once per tool. Each call wraps the tool schema in a dummy conversation, then sums the totals:

```json
"messages": [{ "role": "user", "content": "foo" }],
"tools": [{ ...single tool schema... }]
```

The wrapper adds ~460 tokens even when the tool itself is only ~130 tokens, and Anthropic also injects its own system instructions for tool use. When the CLI iterates over 60 tools, it incurs that preamble and wrapper 60 times, then sums those inflated totals for `/context`. The real request includes the tool list once, so those instructions and the wrapper should be counted once.

### Minimal MCP server experiment

| Variant                              | Local tokenizer | `count_tokens` (one request) | `/context` (per-tool sum) |
| ------------------------------------ | --------------- | ---------------------------- | ------------------------- |
| Single `echo_tool` ("Echoes input.") | 131             | 587                          | 587                       |
| Two `echo_tool`s batched together    | 261             | 672                          | 1,167 (≈587 + 580)        |

When two tools are counted together, `count_tokens` returns 672 tokens--far less than the 1,167 you get when each tool is counted separately and the results are summed. The overhead is shared once per request, but `/context` ignores that sharing and repeats it per tool.

### Reproduction steps (API-only)

Anyone with an Anthropic API key can reproduce the numbers without Claude Code:

1. **Baseline (8 tokens).**

```bash
curl https://api.anthropic.com/v1/messages/count_tokens?beta=true \
  -H "anthropic-version: 2023-06-01" \
  -H "Authorization: Bearer $CLAUDE_API_KEY" \
  -d '{"model":"claude-sonnet-4-5-20250929","messages":[{"role":"user","content":"foo"}]}'
```

2. **Single tool (~587 tokens).** Add the `echo_tool` schema from earlier to the `tools` array and rerun the request.

3. **Two tools batched (~672 tokens).** Add the second tool to the same array and rerun; the total should increase by only ~85 tokens.

4. **Per-tool summation (~1,167 tokens).** Call `count_tokens` separately for each tool (or run Claude Code's `/context`), then add the results together. The total roughly doubles because the shared instructions are counted twice.

5. **Full XcodeBuildMCP (15,282 vs. 45,018 tokens).** Send one `count_tokens` request with all sixty tools or rely on `/context`; the same 30k-token gap appears, matching the table above.

## Why the prompt grows in the first place

Anthropic's documentation explains that every request with tools adds a platform-supplied preamble so the model knows when and how to invoke them. Those instructions are injected by the platform, not by the client, and they are opaque to the `/context` accounting.

Anthropic is explicit about this in their guidance: "When you use tools, we also automatically include a special system prompt for the model which enables tool use. The number of tool use tokens required for each model are listed below (excluding the additional tokens listed above). Note that the table assumes at least 1 tool is provided. If no tools are provided, then a tool choice of none uses 0 additional system prompt tokens." (Source: https://platform.claude.com/docs/en/agents-and-tools/tool-use/overview)

The same page lists the per-request system prompt cost. For Claude Sonnet 4.5 the tool use system prompt adds 346 tokens when the model can auto-select tools and 313 tokens when a specific tool is chosen. Counting each tool separately multiplies that 313-346 token preamble by the number of tools. My measurements match this: a single tool is 131 raw tokens, 587 once the platform preamble is applied, and 456 of that is system instructions plus wrapper. Two tools in one request land at 672 tokens, but counting them separately and summing gives 1,167, adding 906 tokens of duplicated platform text. With XcodeBuildMCP's 60 tools, the real combined request is 15,282 tokens, yet `/context` sums to 45,018, implying 30,937 tokens of duplicated system prompt and wrapper—almost exactly 60 times the 456-token per-tool overhead seen in the one-tool case.

> The 313-346 token system prompt, multiplied per tool, explains most of the overcount; the rest is the tiny wrapper `count_tokens` adds around each single-tool call.

## What remains true about MCP costs

The correction does not absolve MCP servers from consuming context:

- The XcodeBuildMCP tool surface is still ~16k tokens. That is a significant portion of a 100k window.
- Claude Code's built-in tools add another ~10k tokens.
- Loading everything at session start means even a "hello" prompt can cost ~25k tokens before the model can reply.

The point is narrower: `/context` significantly overstates MCP usage because it sums per-tool measurements that each include duplicate platform system instructions and wrapper text.

## Closing

The data shows that Claude Code's `/context` reporting conflates real tool cost with measurement overhead, inflating MCP totals by roughly 3x in my case. MCP servers still have non-trivial context footprints, but the diagnostic bug has convinced many developers to abandon MCP entirely even though the actual payloads are materially smaller than the UI suggests. A clearer accounting does not make MCPs universally good or bad; it simply establishes what they truly cost so we can decide--project by project--whether keeping them enabled makes sense.
